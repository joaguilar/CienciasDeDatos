---
title: "Tarea 3"
author: "Jose Aguilar, Eilyn Salazer, Crisia Piedra"
date: "May 6, 2020"
output: 
  html_document: 
    toc: yes
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if(!require(arules)) install.packages("arules",dependencies = TRUE,repos=c(CRAN="https://cran.cnr.berkeley.edu/"))
library(arules)
if(!require(readxl)) install.packages("readxl",dependencies = TRUE,repos=c(CRAN="https://cran.cnr.berkeley.edu/"))
library("readxl")
library(ggplot2)
library(knitr)
if(!require(kableExtra)) install.packages("kableExtra",dependencies = TRUE,repos=c(CRAN="https://cran.cnr.berkeley.edu/"))
library(kableExtra)
library(arules)
library(arulesViz)

library(tidyverse)
if(!require(plyr)) install.packages("plyr",dependencies = TRUE)
library(plyr); library(dplyr)
library(ggplot2)
library(knitr)
library(lubridate)
if(!require(assertr)) install.packages("assertr",dependencies = TRUE)
library(assertr)
if(!require(reshape2)) install.packages("reshape2",dependencies = TRUE)
library(reshape2)

```

# Entendimiento del negocio

## Objetivos de minería de datos 

*	Identificar los 3 clústers de datos más comunes entre los miembros de la comunidad.
*	Determinar las 3 caracteristicas más comunes entre los miembros de la comunidad para la participación en grupos.

## Criterios de éxito desde la perspectiva de minería de datos

* Evaluar la confianza del modelo priori con el fin de validar que la confianza de las reglas seleccionadas sea mayor al 90%.

#	Entendimiento de los datos

El conjunto de datos seleccionado cuenta con 3484 observaciones capturadas a través de la entrevista realizada por el alcalde el cual evalua 12 atributos o variables, las caracteristicas de estos datos recopilados se describen a continuación.

## Exploración de los datos 

El conjunto de datos encuesta.csv contiene los siguientes campos:

```{r warning=FALSE}
setwd('C:/Curso TEC/Tarea3/CienciasDeDatos/05_Mineria_De_Datos/Tarea3')
atributos<-read.csv('descripcion_atributos.csv', sep = ',',dec = '.')
kable(atributos[,0:3])

```

## Verificación de la calidad de datos

Para la evaluación de la calidad de los datos, se emplea la función summary para identificar la presencia de valores nulos, así como valores minimos y máximos de las variables númericas a fin de validar,
si a simple vista es posible encontrat outliers o valores fuera de rango, como valores negativos.

```{r warning=FALSE}
dataset<-read.csv('Encuesta.csv', sep = ',',dec = '.')
str(dataset)
summary(dataset)
```
 
#	Preparación de los datos 

La primera conversión sería convertir las columnas Trabaja y Familia a un valor numérico para que sea consistente con las demás variables:

```{r warning=FALSE}
# Lo convertimos usando as.integer(), pero debemos restarle 1 para que quede con dos valores 0 y 1, en vez de 1 y 2 como funciona al convertir de factor a entero
dataset$Trabaja1 <- as.integer(dataset$Trabaja)-1
dataset$Familia <- as.integer(dataset$Familia)-1
dataset$Familia<- factor(dataset$Familia,labels=c("NoFamilia","SiFamilia"))
dataset$Trabaja<- factor(dataset$Trabaja,labels=c("NoTrabaja","SiTrabaja"))
dataset$Hobbies<- factor(dataset$Hobbies,labels=c("NoHobbies","SiHobbies"))
dataset$Club_Social<- factor(dataset$Club_Social,labels=c("NoClub_Social","SiClub_Social"))
dataset$Politica<- factor(dataset$Politica,labels=c("NoPolitica","SiPolitica"))
dataset$Profesional<- factor(dataset$Profesional,labels=c("NoProfesional","SiProfesional"))
dataset$Medioambiente<- factor(dataset$Medioambiente,labels=c("NoMedioambiente","SiMedioambiente"))
dataset$Grupo_Apoyo<- factor(dataset$Grupo_Apoyo,labels=c("NoGrupo_Apoyo","SiGrupo_Apoyo"))
str(dataset)
```

Renombramos los valores de las variables Sexo y Tiempo_Comunidad:

```{r warning=FALSE}
dataset$Tiempo_comunidad<-revalue(dataset$Tiempo_comunidad,c("Corto"="Tiempo_comunidad_Corto","Largo"="Tiempo_comunidad_Largo","Medio"="Tiempo_comunidad_Medio"))
dataset$Sexo<-revalue(dataset$Sexo,c("F"="Sexo_F","M"="Sexo_M"))
summary(dataset)

```

Graficos de distribucion de los valores de las variables que son factores:

```{r warning=FALSE}

dataset_factors =dataset[,sapply(dataset, is.factor)]

for (f_name in colnames(dataset[,sapply(dataset, is.factor)])){
  print(f_name)
  barplot(prop.table(table(dataset[,f_name])),main = paste("Distribución de ",f_name),
          space = 1.2, axisnames = TRUE, col = rainbow(3))
}


```

## Selección de los datos 

Para seleccionar los datos a utilizar, vamos a revisar la distribución de los valores en las diferentes columnas utilizando el comando summary:

```{r warning=FALSE}
summary(dataset)
```

Revisando los datos, podemos observar que en dos variables _Club_Social_ y _Politica_ existe un desbalance importante en la distribución de los valores, con mas del 80% de las observaciones con un solo valor:

| Variable | Si (%) | No (%) |
|---|---|---|
| Club_Social | 10.36 | 89.64 |
| Politica | 18.87 | 81.13 |

Debido a esto, no seran consideramos para el análisis.

```{r warning=FALSE}
dataset$Club_Social <- NULL
dataset$Politica <- NULL
dataset$Trabaja1 <- NULL
```


## Limpieza de los datos 

Para asegurar el correcto funcionamiento del algoritmo, vamos a eliminar las filas que contengan valores nulos.

```{r warning=FALSE}
dataset<- na.omit(dataset)
```

## Construcción de nuevos datos (atributos) 

Se crearon dos nuevas variables como el rango de edad y el timepo de respuesta para agrupar los datos

```{r warning=FALSE}
dataset$Grupo_Edad<-discretize(dataset$Edad,method="frequency",breaks = 3, labels = c("Edad_Joven","Edad_Media","Edad_Mayor"))
levels(dataset$Grupo_Edad)

dataset$Grupo_Tiempo_Respuesta<-discretize(dataset$Tiempo_Respuesta,method="frequency",breaks = 3, 
                                           labels = c("Tiempo_Respuesta_Rapida","Tiempo_Respuesta_Media","Tiempo_Respuesta_Lenta"))
levels(dataset$Grupo_Tiempo_Respuesta)

str(dataset)

colnames(dataset)

```

## Transformaciones aplicadas a los datos 
 
(Si la preparación de los datos la realiza en un lenguaje de programación distinto a R, debe documentar los cambios o transformaciones aplicadas a los datos, aportando screenshots y agregándolos como imágenes en el documento RMarkdown.)

En este caso todo el desarrollo de la tarea se realiza a través de R.
 
#	Fase de modelado  

(estas actividades debe realizarlas para cada conjunto de reglas generado) 

## Selección de técnicas (en este caso A priori)

## Construcción del modelo (en este caso serán conjuntos de reglas) 

### Modelo 1
####	Selección de los parámetros 

Para la creación del primer conjunto de reglas se hace uso de todas originales (excepto Politica y  Club Social) a fin de explorar los resultados de las reglas generadas.

```{r warning=FALSE}
todasvariables <- dataset[,1:10]
transacciones<- ddply(todasvariables, c("Tiempo_Respuesta","Tiempo_comunidad","Sexo","Trabaja","Edad","Familia","Hobbies","Profesional","Medioambiente","Grupo_Apoyo"),function(todasvariables) paste(todasvariables$item,collapse = ','))

#transacciones <- paste(dataset$Tiempo_Respuesta,dataset$Tiempo_comunidad,dataset$Sexo,dataset$Trabaja,
#                       dataset$Edad,dataset$Familia,dataset$Hobbies,dataset$Club_Social,dataset$Politica,
#                       dataset$Profesional,dataset$Medioambiente,dataset$Grupo_Apoyo,collapse=',')
#dataset$Tiempo_Respuesta<-NULL
#dataset$Edad<-NULL

#transacciones <- col_concat(dataset,sep=",")
transacciones<-as(dataset,Class = "transactions")
head(transacciones)
 
 # se guardan los datos como archivo csv en formato transaccion
write(transacciones,'transaccionesOR2.csv',sep=',')
#write.csv(transacciones,'transaccionesOR2.csv',quote = FALSE)

```


##### Exploración de las transacciones
```{r}
summary(transacciones)
```

####	Ejecución (generación de reglas, eliminación de subconjuntos,etc) 

##### Generación de las reglas usando A priori

```{r}
 # se generarn las reglas usando el algoritmo a priori, con un soporte del 1% y una confianza de 0.9 o 90%

  reglas<- apriori(transacciones,parameter = list(supp=0.001,conf=0.9,maxlen=10))
  
  inspect(reglas[1:10])

   # Generar menos reglas
  #reglas<- apriori(transacciones,parameter = list(supp=0.001,conf=0.8,maxlen=3))
  #inspect(reglas[1:10])
 
  # eliminar reglas que son subconjuntos de otras 
  subconjuntos<- which(colSums(is.subset(reglas,reglas))>1)
  
  reglasFinal<- reglas[-subconjuntos]
  #inspect(reglasFinal[1:10])
  
  # se ordena por soporte y se observan las primeras 10 reglas
  inspect(sort(reglasFinal,by='lift',decreasing = TRUE)[1:10])
  
  # se filtran las reglas con confianza superior a 0.25
  mejoresReglas<- reglasFinal[quality(reglasFinal)$confidence>0.90]
  
```

```{r warning=FALSE}
# se leerá el archivo como transacciones formato basket
 transacciones<- read.transactions('transaccionesOR2.csv',sep=',',format = 'basket')
 
```
####	Descripción general de las reglas obtenidas (incluya al menos un gráfico) 

##### Visualización de las 3 mejores reglas (según confianza) - grafo
```{r fig.align='center'}
   tresMejoresReglas<- head(mejoresReglas,n=3,by='lift')
   plot(tresMejoresReglas,method = 'graph',engine = 'htmlwidget')
```
##### Visualización de  20 reglas - gráfico paracoord
```{r}
# graficar 10 reglas individuales para observar lhs y rhs
  Top3<-head(mejoresReglas,n=3,by='confidence')
  plot(Top3,method ='paracoord')
```


### Evaluación de los modelos 

####	Muestre e interprete las mejores 3 reglas de cada conjunto generado 

Las mejores reglas al utilizar todas las siguientes:

```{r}
inspect(Top3)
```

La primera regla nos indica que si la persona tiene poco tiempo en la comunidad, tiene hobbies, pertenece a un grupo de apoyo, y respondió la encuesta en el grupo más largo, significa que la persona trabaja.

### Modelo 2
####	Selección de los parámetros 

Para la creación del primer conjunto de reglas se hace uso de todas originales (excepto Politica y  Club Social) a fin de explorar los resultados de las reglas generadas.

```{r warning=FALSE}

transacciones<- ddply(dataset, c("Grupo_Tiempo_Respuesta","Tiempo_comunidad","Sexo","Trabaja","Grupo_Edad","Familia","Hobbies","Grupo_Apoyo"),function(dataset) paste(dataset$item,collapse = ','))

#transacciones <- paste(dataset$Tiempo_Respuesta,dataset$Tiempo_comunidad,dataset$Sexo,dataset$Trabaja,
#                       dataset$Edad,dataset$Familia,dataset$Hobbies,dataset$Club_Social,dataset$Politica,
#                       dataset$Profesional,dataset$Medioambiente,dataset$Grupo_Apoyo,collapse=',')
#dataset$Tiempo_Respuesta<-NULL
#dataset$Edad<-NULL

#transacciones <- col_concat(dataset,sep=",")
transacciones<-as(dataset,Class = "transactions")
head(transacciones)
 
 # se guardan los datos como archivo csv en formato transaccion
write(transacciones,'transaccionesOR2.csv',sep=',')
#write.csv(transacciones,'transaccionesOR2.csv',quote = FALSE)

```


##### Exploración de las transacciones
```{r}
summary(transacciones)
```

####	Ejecución (generación de reglas, eliminación de subconjuntos,etc) 

##### Generación de las reglas usando A priori

```{r}
 # se generarn las reglas usando el algoritmo a priori, con un soporte del 1% y una confianza de 0.9 o 90%

  reglas<- apriori(transacciones,parameter = list(supp=0.001,conf=0.9,maxlen=10))
  
  inspect(reglas[1:10])

   # Generar menos reglas
  #reglas<- apriori(transacciones,parameter = list(supp=0.001,conf=0.8,maxlen=3))
  #inspect(reglas[1:10])
 
  # eliminar reglas que son subconjuntos de otras 
  subconjuntos<- which(colSums(is.subset(reglas,reglas))>1)
  
  reglasFinal<- reglas[-subconjuntos]
  #inspect(reglasFinal[1:10])
  
  # se ordena por soporte y se observan las primeras 10 reglas
  inspect(sort(reglasFinal,by='lift',decreasing = TRUE)[1:10])
  
  # se filtran las reglas con confianza superior a 0.25
  mejoresReglas<- reglasFinal[quality(reglasFinal)$confidence>0.90]
  
```

```{r warning=FALSE}
# se leerá el archivo como transacciones formato basket
 transacciones<- read.transactions('transaccionesOR2.csv',sep=',',format = 'basket')
 
```
####	Descripción general de las reglas obtenidas (incluya al menos un gráfico) 

##### Visualización de las 3 mejores reglas (según confianza) - grafo
```{r fig.align='center'}
   tresMejoresReglas<- head(mejoresReglas,n=3,by='lift')
   plot(tresMejoresReglas,method = 'graph',engine = 'htmlwidget')
```
##### Visualización de  20 reglas - gráfico paracoord
```{r}
# graficar 10 reglas individuales para observar lhs y rhs
  Top3<-head(mejoresReglas,n=3,by='confidence')
  plot(Top3,method ='paracoord')
```


### Evaluación de los modelos 

####	Muestre e interprete las mejores 3 reglas de cada conjunto generado 

Las mejores reglas al utilizar todas las siguientes:

```{r}
inspect(Top3)
```
