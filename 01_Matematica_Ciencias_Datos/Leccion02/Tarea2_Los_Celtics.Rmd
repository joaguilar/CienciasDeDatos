---
title: "Tarea 2 - Anova"
author: "Los Celtics"
date: "9 de Abril, 2019"
output:
  pdf_document: 
    keep_tex: true
---

```{r setup, include=FALSE}
if (!require(kableExtra)){
        install.packages("kableExtra",dependencies = TRUE,repos=c(CRAN="https://cran.cnr.berkeley.edu/"))
}
if(!require(devtools)) install.packages("devtools")
devtools::install_github("kassambara/ggpubr")
if(!require(ggpubr)) install.packages("ggpubr")
library(knitr)
library(kableExtra)
options(knitr.table.format = "latex")
knitr::opts_chunk$set(echo = TRUE)
```

## Carga de datos

```{r, cache=TRUE}
algodon <- read.csv("algodon.csv", header = TRUE, row.names = 1)
```

Datos Cargados:

```{r, cache=TRUE}
kable(algodon)
```

## Limpieza de datos

Los datos cargados no cumplen con los estándares de _Tidy Data_ https://vita.had.co.nz/papers/tidy-data.pdf para el análisis, por lo que es necesario al menos hacer un cambio - cambiar las observaciones (experimentos) a filas, y mantener las variables independientes a columnas. Afortunadamente, esto lo podemos hacer facilmente haciendo la transpuesta:

```{r}
algodon_t <- as.data.frame(t(algodon))
kable(algodon_t)
```

## ANOVA

Calculo de ANOVA:

```{r, cache=TRUE}
algodon_stacked <- stack(algodon_t)
kable(algodon_stacked)
```

```{r}
library(ggpubr)
ggboxplot(algodon_stacked, x="ind", y = "values", color = "ind", order = c("Porc_15", "Porc_20", "Porc_25", "Porc_30", "Porc_35"), ylab = "libra/pulg^2", xlab = "% de Algodón")

ggline(algodon_stacked, x= "ind", y = "values", add = c("mean_se", "jitter"), order = c("Porc_15", "Porc_20", "Porc_25", "Porc_30", "Porc_35"), ylab = "libra/pulg^2", xlab = "% de Algodón")
```



```{r, cache=TRUE}
anova_algodon <- aov(values ~ ind, data = algodon_stacked, qr = TRUE)
summary(anova_algodon)

```

```{r}
anova_algodon
```

De aquí podemos decir que:

$$F(4,20)=14.76, p < 0.001$$

Tenemos los grados de libertad $4$ (numerador) y $20$ (denominador), asi como un $p$ menor a $0.001$. Con estos datos podemos buscar en la tabla de Fischer para $p<0.001$:
\renewcommand{\figurename}{Fig.}
```{r, out.width="0.3\\linewidth", include=TRUE, fig.align="center", fig.cap=c("Tabla de Fisher p < 0.001"), echo=FALSE}
knitr::include_graphics("ftable001.PNG")
```
Tabla tomada de https://web.ma.utexas.edu/users/davis/375/popecol/tables/f0001.html

Para estos valores del _F-Test_, al buscarlos en la tabla nos da que el valor cr�tico es $7.10$. Nuestro _F-Test_ da un resultado de $14.76$, que es mayor que el valor cr�tico, lo que significa que al menos un tratamiento tiene un efecto medible sobre las observaciones y es un resutlado estad�sticamente v�lido.

La explicaci�n de lo anterior es:

ANOVA lo que hace es calcular varianzas. Estas varianzas nos indican cuán alejados están los datos de la media, es decir, la dispersión de los datos. Entre más grande sea la varianza, significa que los datos están más lejos.

El _F-test_ lo que indica es la razón entre las varianzas de las medias de la muestra y de las varianzas de los errores de las observaciones de la muestra. La idea es que la varianza de las medias debería de ser similar a la varianza de las observaciones en caso que las diferencias de las observaciones sean por errores, dado que tienen el mismo origen. De no ser así, la varianza de al menos un grupo de medias sería mucho mayor que la varianza entre las muestras, porque habría otro factor que está afectando solamente a ese grupo.

Tomando el ejemplo visto en clase, si partimos que cada observación se compone de tres partes:

$$ y_{ij} = \mu + \tau_i + \epsilon_{ij} $$

$\mu$ = la media
$\tau$ = Efecto del i-ésimo tratamiento
$\epsilon$ = error de la observación

Tal y como vimos en clase, de esto podemos deducir dos hipótesis:

- Hipótesis nula $H_0$: los efectos de los tratamientos no afectan, es decir, la media de todos los tratamientos es la misma, y todo puede ser explicado por $\mu + \epsilon_{ij}$
- Hipótesis alternativa $H_1$: Los efectos de los tratamientos si afectan, por lo tanto en al menos un par de tratamientos $(i,j)$, $\mu_i \neq \mu_j$

Para probar estas hipótesis, ANOVA lo que hace es calcular la dispersión de las medias, y dividirlas por la dispersion de todas las observaciones. Si $\tau_i=0 \forall i$, entonces la dispersión de todas las medias y la dispersión de todas las observaciones sería la misma, y el _F test_ daría 1. De lo contrario daría un número mayor que uno, al afectar $\tau$ al menos a uno de los tratamientos moviendo un poco la dispersión.

Adicionalmente, ANOVA utiliza los _grados de libertad_. En el caso de variables categoricas, como en este caso, para las medias se calcula como uno menos que el numero de niveles $DF_k=k-1$. En el caso del error, se calcula como el numero de observaciones menos el numero de niveles (o grupos) usados $DF_n=n-k$.


El c�lculo que realiza ANOVA es el siguiente:

$$

F=CMF

$$


- Lo llamado los _mean squares_. Estos son 

Esto se ve reflejado dentro de los datos en el objeto ANOVA:


