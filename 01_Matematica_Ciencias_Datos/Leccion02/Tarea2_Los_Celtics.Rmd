---
title: "Tarea 2 - Anova"
author: "Los Celtics"
date: "9 de Abril, 2019"
output:
  pdf_document: 
    keep_tex: true
---

```{r setup, include=FALSE}
if (!require(kableExtra)){
        install.packages("kableExtra",dependencies = TRUE,repos=c(CRAN="https://cran.cnr.berkeley.edu/"))
}
if(!require(devtools)) install.packages("devtools")
devtools::install_github("kassambara/ggpubr")
if(!require(ggpubr)) install.packages("ggpubr")
library(knitr)
library(kableExtra)
options(knitr.table.format = "latex")
knitr::opts_chunk$set(echo = TRUE)
```

## Carga de datos

```{r, cache=TRUE}
algodon <- read.csv("algodon.csv", header = TRUE, row.names = 1)
```

Datos Cargados:

```{r, cache=TRUE}
kable(algodon)
```

## Limpieza de datos

Los datos cargados no cumplen con los estándares de _Tidy Data_ https://vita.had.co.nz/papers/tidy-data.pdf para el análisis, por lo que es necesario al menos hacer un cambio - cambiar las observaciones (experimentos) a filas, y mantener las variables independientes a columnas. Afortunadamente, esto lo podemos hacer facilmente haciendo la transpuesta:

```{r}
algodon_t <- as.data.frame(t(algodon))
kable(algodon_t)
```

## ANOVA

Calculo de ANOVA:

```{r, cache=TRUE}
algodon_stacked <- stack(algodon_t)
kable(algodon_stacked)
```

```{r}
library(ggpubr)
ggboxplot(algodon_stacked, x="ind", y = "values", color = "ind", order = c("Porc_15", "Porc_20", "Porc_25", "Porc_30", "Porc_35"), ylab = "libra/pulg^2", xlab = "% de Algodón")

ggline(algodon_stacked, x= "ind", y = "values", add = c("mean_se", "jitter"), order = c("Porc_15", "Porc_20", "Porc_25", "Porc_30", "Porc_35"), ylab = "libra/pulg^2", xlab = "% de Algodón")
```



```{r, cache=TRUE}
anova_algodon <- aov(values ~ ind, data = algodon_stacked, qr = TRUE)
summary(anova_algodon)

```

```{r}
anova_algodon
```

De aquí podemos decir que:

$$F(4,20)=14.76$$

Este _F-Test_ da un valor mayor que uno, lo que significa, en resumen, que al menos un tratamiento tiene un efecto medible sobre las observaciones.

La explicación de lo anterior es:

ANOVA lo que hace es calcular varianzas. Estas varianzas nos indican cuán alejados están los datos de la media, es decir, la dispersión de los datos. Entre más grande sea la varianza, significa que los datos están más lejos.

El _F-test_ lo que indica es la razón entre las varianzas de las medias de la muestra y de las varianzas de los errores de las observaciones de la muestra. La idea es que la varianza de las medias debería de ser similar a la varianza de las observaciones en caso que las diferencias de las observaciones sean por errores, dado que tienen el mismo origen. De no ser así, la varianza de al menos un grupo de medias sería mucho mayor que la varianza entre las muestras, porque habría otro factor que está afectando solamente a ese grupo.

Tomando el ejemplo visto en clase, si partimos que cada observación se compone de tres partes:

$$ y_{ij} = \mu + \tau_i + \epsilon_{ij} $$

$\mu$ = la media
$\tau$ = Efecto del i-ésimo tratamiento
$\epsilon$ = error de la observación

Tal y como vimos en clase, de esto podemos deducir dos hipótesis:

- Hipótesis nula $H_0$: los efectos de los tratamientos no afectan, es decir, la media de todos los tratamientos es la misma, y todo puede ser explicado por $\mu + \epsilon_{ij}$
- Hipotesis alternativa $H_1$: Los efectos de los tratamientos si afectan, por lo tanto en al menos un par de tratamientos $(i,j)$, $\mu_i \neq \mu_j$

Para probar estas hipótesis, ANOVA lo que hace es calcular la dispersión de las medias, y dividirlas por la dispersion de todas las observaciones. Si $\tau_i=0 \forall i$, entonces la dispersión de todas las medias y la dispersión de todas las observaciones sería la misma, y el _F test_ daría 1. De lo contrario daría un número mayor que uno, al afectar $\tau$ al menos a uno de los tratamientos moviendo un poco la dispersión.

Estas varianzas las calcula ANOVA de la siguiente forma:

Adicionalmente, ANOVA utiliza los _grados de libertad_. Estos son basicamente cuanta informacion utiliza el modelo. En el caso de variables categoricas, como en este caso, para las medias se calcula como uno menos que el numero de niveles: $DF_k=k-1$. En el caso del error, se calcula como el numero de observaciones menos el numero de niveles (o grupos) usados: $DF_n=n-k$.


- Lo llamado los _mean squares_. Estos son 

Esto se ve reflejado dentro de los datos en el objeto ANOVA:

```{r, cache=TRUE}
print(summary(anova_algodon)[[1]][["Sum Sq"]][[1]])
```

```{r, cache=TRUE}
str(anova_algodon)
```



y

$$p = 9.13e-06 < 0.05$$

Al ser $p < 0.05$, podemos decir que los resultados son significativos, y no fueron obtenidos aleatoriamente.



